Retrieval augmented generation (RAG)Â is a technique for improving the quality of LLM output by grounding it with sources of knowledge not available in the trained model.

Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by giving them access to external, up-to-date, or proprietary information. Instead of retraining the LLM, RAG dynamically retrieves relevant data from a separate knowledge base (your personal dataset) based on a user's query. This retrieved context is then injected directly into the prompt, allowing the LLM to generate more accurate, relevant, and grounded responses without being explicitly trained on that specific data.

[[RAG Working.png]]




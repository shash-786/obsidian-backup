**A large language model**, or LLM, is a type of AI model that is trained on massive amounts of text data to understand and generate human-like language and insights.


Types of Models
1) _Traditional Model_ - Non-generative AI models are often trained on task-specific datasets with supervised learning. Training data is labeled, and you let the AI discover the rules. For example, you might train the traditional AI model using many pictures of cats and other animals. The model learns the pattern, and predicts whether a new picture is a cat. This type of learning is typically used to solve a specific task.
2) _Foundation Model_ - With generative AI, you feed a foundational model a huge amount of multimodal data. ***Multimodal data refers to information that comes in multiple formats, like text, images, audio, video, and numerical data***. Without any supervision, the foundational model learns a seemingly endless number of concepts. So the foundational model can be adapted for many different purposes. This type of learning allows the foundational model to acquire knowledge and skills that can be adapted to a wide range of tasks. Foundation models can generate text, create content, and answer questions.




